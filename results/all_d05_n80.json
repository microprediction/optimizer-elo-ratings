{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [7, 7, 4, 48, 7, 4, 67, 54, 48, 59, 54, 34, 55, 56, 52, 56, 70, 58, 0, 0, 0, 0, 0, 0, 52, 0, 0, 0, 0, 63, 62, 55, 53, 58, 76, 60, 66, 62, 61, 51, 50, 104, 58, 0, 0, 47, 76, 65, 71, 72, 56, 50, 52, 75, 51, 59, 60, 43, 71, 72, 66, 48, 38, 52, 61, 33, 44, 17, 16], "rating": [1426.8186025849968, 1461.6971350574072, 1473.5595771104738, 1178.559504603622, 1436.724750929581, 1556.2637618827353, 1838.5613503415177, 1681.6951772969712, 1201.2518005611603, 2079.0696365922067, 1981.543295723855, 1930.238626834306, 1676.4373965177397, 1763.7611524905324, 1600, 1600, 1600, 1611.2081132012543, 1600, 1600, 1600, 1600, 1600, 1600, 1281.0442951339453, 1600, 1600, 1600, 1600, 1624.6090231635594, 1551.364088012117, 1364.354007833935, 1342.4292920020068, 1823.2675209465945, 1032.584581760242, 1671.6038310314864, 1734.734289499417, 1493.488485626163, 1530.6570269556557, 2027.9406261685403, 1448.4443438732815, 1453.616648290498, 1718.989427112223, 1600, 1600, 1900.8993236426497, 1312.596012662908, 1840.2410896859683, 1702.9200928557518, 1899.1056334144691, 1927.3120816046455, 1873.7409412267345, 2017.770260620345, 1991.2974404114887, 1813.0970557469059, 1490.7969625686203, 1643.7688618455295, 1440.9629116552524, 1286.3017263304064, 1243.5608186543936, 1832.7753058087792, 1518.3383559500742, 1761.0528486469968, 2020.4052324363158, 2147.4397198952897, 1773.0506458725897, 1819.3560289094833, 1766.037986069391, 1577.3197085074016], "traceback": ["passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/scipycube.py\", line 40, in scipy_powell_cube\n    return scipy_cube(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='powell')\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/scipycube.py\", line 29, in scipy_cube\n    result = minimize(_objective, x0=[0]*n_dim, method=options['method'],bounds=bounds, options=options)\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 614, in minimize\n    return _minimize_powell(fun, x0, args, callback, bounds, **options)\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 3059, in _minimize_powell\n    fx2 = squeeze(func(x2))\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 464, in function_wrapper\n    return function(np.copy(x), *(wrapper_args + args))\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/scipycube.py\", line 27, in _objective\n    return objective(list(x))\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 174, in markowitz_return_on_cube\n    return realized_something_factory(g=g,u=u, adjust=True)\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 121, in realized_something_factory\n    w = cube_to_weights(u)\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 108, in cube_to_weights\n    raise ValueError(\"u should be in hypercube\")\nValueError: u should be in hypercube\n", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing"], "active": [true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false]}