{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [1, 1, 0, 36, 4, 2, 56, 39, 37, 49, 40, 34, 43, 40, 35, 42, 45, 37, 0, 0, 0, 0, 0, 0, 41, 0, 0, 0, 0, 46, 43, 41, 36, 41, 63, 48, 49, 48, 45, 33, 39, 88, 46, 0, 0, 39, 57, 43, 48, 53, 41, 38, 38, 56, 40, 46, 49, 33, 57, 55, 54, 36, 29, 36, 40, 33, 44, 17, 16], "rating": [1579.4227614433619, 1612.210950226991, 1600, 1198.7686020528226, 1491.0209016645501, 1614.9035619754236, 1783.5617154795546, 1640.0660939110924, 1259.4922904412183, 2045.2588191785992, 1977.8007220237625, 1930.238626834306, 1671.2202810136198, 1757.1701324638939, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1301.117310159731, 1600, 1600, 1600, 1600, 1649.1076329252735, 1451.0795877099006, 1337.1409285644236, 1314.276829037236, 1772.9245916134832, 1074.684517952513, 1684.156940477983, 1629.339435490983, 1477.8680093182625, 1520.0572279537546, 1932.4129580276303, 1394.8103647002984, 1398.3989670766598, 1667.86750902659, 1600, 1600, 1837.9626976153802, 1340.6935509843975, 1716.5692175164804, 1682.269923931347, 1843.6891097225903, 1910.1101011176152, 1925.3541284819416, 1971.926776413115, 1917.0775973207988, 1771.262816057307, 1478.422280521673, 1650.4456344716605, 1475.3268149441406, 1244.1525908894016, 1377.9260480509754, 1825.3413695085612, 1543.9687030589173, 1686.2910136181674, 1915.8311380854275, 2017.1481940225358, 1773.0506458725897, 1819.3560289094833, 1766.037986069391, 1577.3197085074016], "traceback": ["passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 76, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/platypuscube.py\", line 73, in platypus_cmaes_cube\n    return platypus_cube(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/platypuscube.py\", line 49, in platypus_cube\n    feasible_solution_obj = sorted([(s.objectives[0], s.variables) for s in algorithm.result if s.feasible],\nAttributeError: 'CMAES' object has no attribute 'result'\n", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 82 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing"], "active": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true]}