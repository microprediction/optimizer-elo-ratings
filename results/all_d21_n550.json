{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_sequential_cube", "hebo_batch_cube"], "count": [0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 0, 2, 0, 3, 0, 0, 0, 0, 2, 2, 1, 3, 0, 1, 0, 0, 1, 2, 3, 0, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0], "rating": [1600, 1600, 1600, 1600.9999778946158, 1600, 1598.9642485340573, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1601.0000190648773, 1600, 1600, 1600, 1600, 1542.06903668361, 1600, 1595.9674422642847, 1600, 1513.0691818094156, 1600, 1600, 1600, 1600, 1540.035773571327, 1601.9991273922424, 1630.0, 1685.933060265905, 1600, 1630.0, 1600, 1600, 1630.0, 1627.96422946918, 1630.9999778946158, 1600, 1571.0357514659427, 1569.964226428673, 1658.9642485340573, 1600, 1600, 1600, 1600, 1571.0357514659427, 1630.0, 1600, 1629.0000221053842, 1600, 1600, 1600, 1600, 1570.0, 1630.0, 1600, 1600, 1600, 1600, 1658.9642485340573, 1570.0, 1570.0, 1631.0357514659427, 1600, 1600, 1600], "traceback": ["not yet run", "not yet run", "not yet run", "Black took 23 function evals when instructed to use 600", "not yet run", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "not yet run", "Black took 551 function evals when instructed to use 551", "passing", "not yet run", "passing", "not yet run", "Black took 600 function evals when instructed to use 600", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "not yet run", "Black took 589 function evals when instructed to use 588", "not yet run", "not yet run", "Black took 601 function evals when instructed to use 600", "passing", "passing", "not yet run", "passing", "passing", "Black took 551 function evals when instructed to use 551", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "not yet run", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/optimizers/bobyqacube.py\", line 39, in bobyqa_noise_cube\n    return bobyqa_cube_factory(objective=objective, n_trials=n_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/optimizers/bobyqacube.py\", line 28, in bobyqa_cube_factory\n    soln = solve(_objective, x0, bounds=(lb, ub), maxfun=n_trials, do_logging=False)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pybobyqa/solver.py\", line 809, in solve\n    solve_main(objfun, x0, args, xl, xu, npt, rhobeg, rhoend, maxfun, nruns, nf, nx, nsamples, params,\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pybobyqa/solver.py\", line 390, in solve_main\n    f_list, num_samples_run, exit_info = control.evaluate_objective(x, number_of_samples, params)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pybobyqa/controller.py\", line 349, in evaluate_objective\n    f_list[i] = eval_objective(self.objfun, remove_scaling(x, self.scaling_changes), self.args, eval_num=self.nf, pt_num=self.nx,\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pybobyqa/util.py\", line 51, in eval_objective\n    f = objfun(x, *args)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/optimizers/bobyqacube.py\", line 26, in _objective\n    return objective(u)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 174, in markowitz_return_on_cube\n    return realized_something_factory(g=g,u=u, adjust=True)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 121, in realized_something_factory\n    w = cube_to_weights(u)\n  File \"/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 108, in cube_to_weights\n    raise ValueError(\"u should be in hypercube\")\nValueError: u should be in hypercube\n", "not yet run", "not yet run"], "active": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true]}