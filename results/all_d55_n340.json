{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "dlib_cube", "dlib_default_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [0, 0, 0, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 108, 105, 129, 109, 122, 118, 145, 97, 0, 136, 119, 107, 116, 107, 120, 147, 121, 128, 134, 128, 120, 138, 126, 126, 121, 140, 127, 111, 243, 120, 119, 0, 0, 0, 0, 0, 110, 0, 120, 121, 119, 119, 136, 116, 129, 122, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], "rating": [1600, 1600, 1600, 1598.4869901719205, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1855.4981256501828, 1600, 1600, 1600, 1600, 1674.1119419896609, 1693.4217843503723, 1826.8831836383658, 1600, 1033.6323986129987, 1779.1685721578474, 947.9233885433144, 1859.1824202550697, 1514.9199160566636, 1113.2411767487001, 1977.5300525665434, 2465.335010538948, 2510.921368395172, 1783.6833156361008, 1556.2630577601717, 2422.264497076304, 2032.6502452432358, 2371.287035687377, 1705.6528953512075, 1808.1667450888067, 1750.0741223470732, 1126.9978470225033, 1555.4192554776475, 1545.1998416898084, 1223.018651722572, 1389.9452676767896, 1600, 1600, 1600, 1600, 1600, 1801.0612575092455, 1600, 1969.4794552501075, 1208.30220816824, 1250.0673775264702, 2260.66867145743, 927.3237058880156, 1125.59070541691, 2476.4312754587377, 2476.1450747723547, 1600, 1600, 1600, 1623.6591623196357, 1600, 1600, 1600, 1600, 1600, 1600], "traceback": ["not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "Black took 341 function evals when instructed to use 341", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 342 function evals when instructed to use 341", "passing", "passing", "passing", "Black took 342 function evals when instructed to use 341", "passing", "passing", "passing", "passing", "passing", "Black took 341 function evals when instructed to use 341", "passing", "Black took 341 function evals when instructed to use 341", "passing", "passing", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "Black took 341 function evals when instructed to use 341", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 77, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/Users/petercotton/virtual/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/Users/petercotton/virtual/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/Users/petercotton/virtual/optimizer-elo-ratings/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 139 function evals when instructed to use 341", "passing", "not yet run", "not yet run", "not yet run", "passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/comparison/eloratings.py\", line 43, in optimizer_game\n    with_count=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 33, in dlib_cube\n    return dlib_default_cube(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count)  # It is useful to have a clone of one of the better algos\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.7/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /private/var/folders/g2/6p5lz9hn36vbnv165bk7yj7r0000gn/T/pip-install-ojjogyqk/dlib_836e2179ea074a8ba6ce68fbb0be6025/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(py::object, const matrix<double, 0, 1> &).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run"], "active": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true]}