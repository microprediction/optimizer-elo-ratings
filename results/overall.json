{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "dlib_cube", "dlib_default_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [196, 191, 228, 751, 109, 277, 640, 634, 627, 647, 646, 467, 602, 1085, 1037, 1090, 1062, 1046, 813, 834, 804, 486, 809, 779, 1080, 797, 797, 813, 835, 1051, 1101, 1066, 1067, 1044, 1114, 1101, 1066, 1095, 1121, 876, 1150, 2231, 913, 808, 0, 626, 648, 623, 634, 1062, 595, 1086, 1066, 1091, 1023, 1006, 1067, 1020, 1022, 818, 815, 490, 823, 693, 675, 353, 403, 78, 207], "rating": [2085.490963382874, 2157.171006153287, 2121.8981064396926, 1711.8459342543783, 1217.6729461096738, 1202.5860832035025, 2253.5965082432276, 2163.009210729853, 1394.1149654497578, 2482.727861436754, 2436.8479754806804, 2285.857667948787, 2123.3139382880504, 2115.8251007768654, 1600, 1600, 1600, 1600, 1574.6369709202513, 1556.1321054403293, 1463.2014358520912, 1305.675601190486, 1218.9516347454664, 1439.0136782492038, 1320.8073908413648, 1696.8106417638808, 1386.426239517699, 1275.1251752221963, 1770.660732258864, 2317.3065697047687, 2455.3365156727173, 1929.2194972161155, 1652.8931397563165, 2548.0459502150647, 1829.2115169979024, 2473.8165013155617, 1853.3405455643428, 1821.8607228886633, 1820.2280732343322, 1995.7923861989584, 1683.3073778772343, 1796.9573091620707, 2176.3114603368504, 1323.221064265359, 1600, 2520.5409034594236, 2451.1862055746915, 2461.3080210171443, 2448.620573594154, 1994.808487550476, 2284.4721696851398, 1804.6706182522296, 1343.590154779126, 1572.9540583550934, 2685.342189156181, 1555.9880212380795, 1863.8417292759743, 2576.7701898079804, 2592.2161593648975, 1392.5689756104448, 1916.914967287584, 2010.1229412299751, 2267.9513342862783, 2343.843504256191, 2680.5975504122357, 2478.7315066681213, 2327.579393042241, 2167.5392962482006, 2183.8944072139075], "traceback": ["passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 551", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "passing", "passing", "Black took 131 function evals when instructed to use 131", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "Black took 133 function evals when instructed to use 133", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /tmp/pip-install-1hguqc5u/dlib_2554f0606f0240e48d06db5b2bcd871d/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(pybind11::object, const dlib::matrix<double, 0, 1>&).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "passing", "passing", "passing", "passing"], "active": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true]}