{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "dlib_cube", "dlib_default_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [184, 180, 211, 686, 97, 246, 602, 605, 590, 615, 612, 467, 570, 1004, 964, 1029, 994, 973, 743, 758, 733, 463, 744, 733, 1010, 730, 743, 753, 784, 979, 1000, 998, 1004, 964, 1033, 1025, 996, 1023, 1044, 813, 1060, 2092, 833, 749, 0, 588, 608, 588, 594, 999, 573, 1013, 994, 1013, 946, 954, 998, 961, 941, 720, 745, 448, 738, 627, 623, 353, 403, 67, 180], "rating": [2052.0993441826754, 2208.8197028260797, 2107.7634798979307, 1551.7800572667675, 1204.647667831919, 1229.346128200126, 2276.3746012031893, 2235.0503861918087, 1328.3430568520243, 2567.461071667663, 2444.3638989074548, 2285.857667948787, 2083.1911915694927, 2168.4062153873065, 1600, 1600, 1600, 1600, 1456.3194352880894, 1501.5532135346891, 1501.099697588479, 1313.249749649289, 1224.9497815348104, 1414.3199907720682, 1274.3790032247632, 1703.7450940788292, 1567.1719398508274, 1287.9360850893388, 1678.3781216195316, 2343.3276711943286, 2458.2960697118237, 1880.4040617695528, 1440.6324073909063, 2506.4102442395338, 1713.2707206755078, 2431.1830855142143, 1856.1252235902207, 1812.336651961403, 1897.3017692678666, 1916.4183096785762, 1690.8145223563386, 1694.0445250825346, 2088.8895756893376, 1342.7092766016372, 1600, 2439.979813139597, 2440.57964363436, 2491.664276678936, 2460.576538848281, 1916.25584979667, 2329.5037763895516, 1879.7500626388262, 1172.1753710648127, 1556.9466530381967, 2728.383031960487, 1517.9719852935857, 1914.4826690065154, 2479.0762233287937, 2552.5518877109366, 1318.5630573974092, 1919.7397288376383, 1929.1569653152806, 2244.988219519039, 2378.96689428896, 2551.747208831294, 2478.7315066681213, 2327.579393042241, 2119.8342537938715, 2149.723830930676], "traceback": ["passing", "passing", "passing", "passing", "passing", "passing", "Black took 81 function evals when instructed to use 81", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 578", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 82 function evals when instructed to use 81", "passing", "passing", "Black took 131 function evals when instructed to use 131", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "passing", "passing", "passing", "passing", "passing", "Black took 341 function evals when instructed to use 341", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 28, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /tmp/pip-install-cjjkfx9f/dlib_1b753bb9cd914e808f578dd5a6d8758c/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(pybind11::object, const dlib::matrix<double, 0, 1>&).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "passing", "passing", "passing", "passing"], "active": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true]}