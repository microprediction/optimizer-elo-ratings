{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_nelder_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_sequential_cube", "hebo_batch_cube", "freelunch_sade_3_cube", "freelunch_sade_8_cube", "freelunch_sade_21_cube", "freelunch_sa_3_cube", "freelunch_sa_8_cube", "freelunch_sa_21_cube", "freelunch_de_3_cube", "freelunch_de_8_cube", "freelunch_de_21_cube", "freelunch_pso_3_cube", "freelunch_pso_8_cube", "freelunch_pso_21_cube", "freelunch_krillherd_3_cube", "freelunch_krillherd_8_cube"], "count": [0, 0, 0, 20, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 32, 37, 33, 29, 30, 21, 19, 23, 0, 18, 24, 23, 33, 16, 28, 15, 35, 41, 33, 31, 35, 34, 26, 34, 33, 36, 27, 23, 50, 19, 27, 0, 0, 37, 19, 0, 36, 0, 0, 0, 40, 29, 26, 0, 28, 26, 16, 21, 20, 17, 45, 30, 0, 0, 11, 12, 8, 7, 9, 5, 11, 5, 5, 6, 3, 6, 0, 0], "rating": [1600, 1600, 1600, 1810.4104938967168, 1593.5800770833257, 1600, 1688.765240543689, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1595.8950766784299, 1600, 1600, 1600, 1600, 1603.697664108258, 1642.1978662722804, 1634.737842012634, 1600, 1350.0797727466838, 1474.737305131531, 1477.9199956662483, 1700.610482185774, 1611.869486035533, 1334.8400357094429, 1617.2977728917954, 1812.4748296235523, 2115.5127264357916, 1652.4304673616584, 1564.2829979265398, 2044.0383292412653, 1712.8172528577022, 2034.564457613858, 1543.0445714929915, 1492.3092252261406, 1301.8964173137597, 1333.4151804214164, 1816.6514124191244, 1813.6330913202496, 1922.6514430786597, 1420.7689973178913, 1600, 1600, 1162.7119916073877, 1560.457544547139, 1600, 1674.3119034776737, 1600, 1600, 1600, 1987.5864849232278, 1944.2091506062097, 1635.4184138779383, 1600, 1618.942151285246, 1320.442616851557, 1652.1902484125653, 1975.5247552103563, 1349.3152730162888, 1409.175386806982, 1986.491174114819, 1971.7429118748091, 1600, 1600, 1500.5406810132163, 1641.3468711902165, 1723.3601878530567, 1596.977169076478, 1697.5469201490057, 1735.735092871, 1395.9320411505914, 1649.8604767264521, 1545.474369315479, 1427.7937128173, 1510.5571661925803, 1543.6233001398264, 1600, 1600], "traceback": ["not yet run", "not yet run", "not yet run", "passing", "passing", "not yet run", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 551", "passing", "not yet run", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 600", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "passing", "passing", "passing", "passing", "not yet run", "not yet run", "passing", "passing", "not yet run", "passing", "not yet run", "not yet run", "not yet run", "passing", "Black took 551 function evals when instructed to use 551", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "Black took 600 function evals when instructed to use 600", "Black took 551 function evals when instructed to use 551", "Black took 607 function evals when instructed to use 600", "passing", "passing", "Black took 551 function evals when instructed to use 551", "Black took 135 function evals when instructed to use 551", "passing", "not yet run", "not yet run", "Black took 558 function evals when instructed to use 555", "passing", "passing", "passing", "passing", "Black took 567 function evals when instructed to use 555", "passing", "Black took 560 function evals when instructed to use 551", "passing", "passing", "Black took 568 function evals when instructed to use 560", "passing", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 76, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 103, in freelunch_krillherd_3_cube\n    return freelunch_factory(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 35, in freelunch_factory\n    runs = optimizer(nruns=1, full_output=True)  # instance and run\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 45, in __call__\n    sols = self.run()\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/optimisers.py\", line 469, in run\n    pop[i].fitness = self.obj(dna)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 89, in w_obj\n    fit = obj(vec)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 22, in _objective\n    return objective(x)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 174, in markowitz_return_on_cube\n    return realized_something_factory(g=g,u=u, adjust=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 121, in realized_something_factory\n    w = cube_to_weights(u)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 108, in cube_to_weights\n    raise ValueError(\"u should be in hypercube\")\nValueError: u should be in hypercube\n", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 108, in freelunch_krillherd_8_cube\n    return freelunch_factory(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 35, in freelunch_factory\n    runs = optimizer(nruns=1, full_output=True)  # instance and run\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 45, in __call__\n    sols = self.run()\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/optimisers.py\", line 469, in run\n    pop[i].fitness = self.obj(dna)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 89, in w_obj\n    fit = obj(vec)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 22, in _objective\n    return objective(x)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 158, in markowitz_skew_on_cube\n    return realized_something_factory(g=g,u=u)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 121, in realized_something_factory\n    w = cube_to_weights(u)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 108, in cube_to_weights\n    raise ValueError(\"u should be in hypercube\")\nValueError: u should be in hypercube\n"], "active": [true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]}