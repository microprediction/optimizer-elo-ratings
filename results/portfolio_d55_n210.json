{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_nelder_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube"], "count": [0, 0, 0, 46, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 149, 165, 160, 175, 152, 170, 159, 147, 0, 163, 173, 166, 165, 160, 179, 161, 143, 153, 150, 167, 149, 167, 174, 147, 160, 165, 0, 174, 308, 0, 175, 0, 0, 50, 59, 0, 57, 0, 0, 0, 0, 0, 162, 0, 171, 145, 143, 156, 163, 160, 157, 154, 0, 0, 0, 0], "rating": [1600, 1600, 1600, 1583.5998217164515, 1600, 1825.8595090044848, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1966.293432631972, 1600, 1600, 1600, 1600, 1521.5693605554586, 1615.4770838282066, 1619.6045203678173, 1600, 1129.7914274597533, 1587.964839382463, 797.6266920174118, 1895.0299579547295, 1423.7944064823353, 1198.010607672716, 2047.5325708857156, 2482.748213876778, 2475.379553479369, 1728.4602251410765, 1621.3131870688685, 2396.63657768199, 2016.1112808860405, 2536.3148286694873, 1920.7440242128596, 2004.8385760714543, 1929.715091828608, 1600, 1178.2117998559859, 1083.5194397605576, 1600, 1311.4245312204985, 1600, 1600, 1133.797678060209, 1656.0117878457638, 1600, 1946.285706587199, 1600, 1600, 1600, 1600, 1600, 1393.6475694263238, 1600, 1988.5754794984107, 1334.238434031919, 1298.987594461585, 2279.145436487569, 648.9233774336634, 756.9053308773774, 2626.7755510369775, 2636.2541481339895, 1600, 1600, 1600, 1600], "traceback": ["not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 212 function evals when instructed to use 211", "Black took 212 function evals when instructed to use 211", "passing", "passing", "passing", "Black took 220 function evals when instructed to use 220", "passing", "passing", "passing", "passing", "passing", "passing", "not yet run", "not yet run", "passing", "passing", "not yet run", "passing", "not yet run", "not yet run", "not yet run", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 76, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 27, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /tmp/pip-install-0foy_g4r/dlib_d2a7a9c4cc144466bd03aa9b90ebcc34/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(pybind11::object, const dlib::matrix<double, 0, 1>&).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "passing", "passing", "passing", "passing", "passing", "Black took 211 function evals when instructed to use 211", "passing", "Black took 190 function evals when instructed to use 211", "not yet run", "not yet run", "not yet run", "not yet run"], "active": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false]}