{"name": ["shgo_slsqp_sobol_cube", "shgo_powell_sobol_cube", "shgo_nelder_sobol_cube", "scipy_slsqp_cube", "scipy_powell_cube", "scipy_nelder_cube", "scipy_lbfgsb_cube", "pysot_ei_cube", "pysot_lcb_cube", "pysot_random_cube", "pysot_srbf_cube", "pysot_dycors_cube", "ax_default_cube", "optuna_cmaes_cube", "optuna_tpe_cube", "optuna_random_cube", "optuna_random_cube_clone", "optuna_random_cube_clone_1", "optuna_random_cube_clone_2", "platypus_genetic_cube", "platypus_evolutionary_cube", "platypus_nsgaii_cube", "platypus_cmaes_cube", "platypus_gde3_cube", "platypus_ibea_cube", "platypus_moead_cube", "platypus_omopso_cube", "platypus_smpso_cube", "platypus_spea2_cube", "platypus_epsmoea_cube", "nevergrad_ngopt_cube", "nevergrad_ngopt4_cube", "nevergrad_de_cube", "nevergrad_portfolio_cube", "nevergrad_oneplus_cube", "nevergrad_hammersley_cube", "nevergrad_ngopt8_cube", "hyperopt_tpe_cube", "hyperopt_atpe_cube", "hyperopt_rand_cube", "pymoo_nelder_cube", "pymoo_nsga3_cube", "pymoo_unsga3_cube", "pymoo_pattern_cube", "pymoo_nsga2_cube", "pymoo_unsga3_cube", "skopt_gp_default_cube", "ultraopt_random_cube", "ultraopt_forest_cube", "ultraopt_gbrt_cube", "ultraopt_etpe_cube", "bayesopt_ucb_cube", "bayesopt_ei_cube", "bayesopt_poi_cube", "dlib_cube", "dlib_default_cube", "nlopt_direct_cube", "nlopt_ags_cube", "nlopt_esch_cube", "nlopt_isres_cube", "nlopt_crs2lm_cube", "nlopt_directr_cube", "nlopt_directo_cube", "nlopt_directl_cube", "bobyqa_default_cube", "bobyqa_noise_cube", "hebo_cube_sequential", "hebo_cube_batch", "hebo_sequential_cube", "hebo_batch_cube", "freelunch_sade_3_cube", "freelunch_sade_8_cube", "freelunch_sade_21_cube", "freelunch_sa_3_cube", "freelunch_sa_8_cube", "freelunch_sa_21_cube", "freelunch_de_3_cube", "freelunch_de_8_cube", "freelunch_de_21_cube", "freelunch_pso_3_cube", "freelunch_pso_8_cube", "freelunch_pso_21_cube", "freelunch_krillherd_3_cube", "freelunch_krillherd_8_cube"], "count": [0, 0, 0, 102, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 173, 199, 197, 183, 229, 170, 169, 191, 0, 169, 167, 190, 165, 189, 180, 191, 180, 203, 188, 179, 193, 191, 188, 196, 176, 189, 199, 176, 352, 162, 190, 0, 0, 61, 73, 0, 80, 0, 0, 0, 0, 0, 173, 0, 165, 191, 174, 190, 178, 179, 206, 180, 0, 0, 0, 0, 4, 8, 8, 8, 9, 7, 6, 9, 3, 4, 4, 5, 0, 0], "rating": [1600, 1600, 1600, 1808.246157277512, 1600, 1831.0770520195194, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1600, 1863.0125415353914, 1600, 1600, 1600, 1600, 1755.4061884070525, 1946.0759408116378, 1946.7080760818171, 1600, 1098.6400364774863, 1873.74128227328, 1211.9414411823243, 1810.6960013553382, 1686.731627294967, 1210.6986611939087, 2155.5612850701004, 2456.4568227115833, 2724.9889750788475, 1947.6367436146222, 1383.1705424035235, 2574.511133616936, 2208.523076172241, 2640.8684073204986, 1601.3441655631907, 1586.2626636642203, 1816.8267521049916, 956.8869078536195, 1752.1799063163587, 1866.9098326194876, 2515.8625867250043, 1419.9540377710857, 1600, 1600, 1079.5446116597097, 1395.69308247979, 1600, 1936.8278519040018, 1600, 1600, 1600, 1600, 1600, 1874.5716106147056, 1600, 1954.7449997847323, 1167.0422056939065, 1130.8522244343062, 2360.2897191666284, 799.9047068902408, 1056.7909228582296, 2701.9122104339785, 2696.32168109732, 1600, 1600, 1600, 1600, 1554.761758387696, 1763.6958431982835, 1627.6343004242876, 1613.4579046355225, 1592.2418131681684, 1802.4364238446874, 1564.6198009640048, 1649.8115501915884, 1682.7993402595125, 1544.8953434642194, 1519.7431557255168, 1662.2080381808964, 1600, 1600], "traceback": ["not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 551", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 600 function evals when instructed to use 600", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "Black took 587 function evals when instructed to use 551", "passing", "not yet run", "not yet run", "passing", "passing", "not yet run", "Black took 551 function evals when instructed to use 551", "not yet run", "not yet run", "not yet run", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 32, in dlib_cube\n    return dlib_default_cube(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count)  # It is useful to have a clone of one of the better algos\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 27, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /tmp/pip-install-m3cj5pb0/dlib_5c84065857a44cf88e65492be181b94a/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(pybind11::object, const dlib::matrix<double, 0, 1>&).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/humpday/optimizers/dlibcube.py\", line 27, in dlib_default_cube\n    best_x, best_val = find_min_global(_objective, lb, ub, n_trials)\nRuntimeError: \n\nError detected at line 63.\nError detected in file /tmp/pip-install-w92e7q2v/dlib_dee35ef4aa2a4450890a31d98877358c/tools/python/src/global_optimization.cpp.\nError detected in function double call_func(pybind11::object, const dlib::matrix<double, 0, 1>&).\n\nFailing expression was 0 < num && num < 35.\nFunctions being optimized must take between 1 and 35 scalar arguments.\n\n", "passing", "Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 41, in optimizer_game\n    white_best_val, white_best_x, white_feval_count = white(objective, n_trials=n_white_trials, n_dim=n_dim,\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 43, in nlopt_ags_cube\n    return nlopt_cube_factory(objective=objective,n_trials=n_trials, n_dim=n_dim, with_count=with_count, method='gn_ags')\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/humpday/optimizers/nloptcube.py\", line 32, in nlopt_cube_factory\n    best_x = opt.optimize([0.5] * n_dim)\n  File \"/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nlopt/nlopt.py\", line 334, in optimize\n    return _nlopt.opt_optimize(self, *args)\nValueError: nlopt invalid argument\n", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 551 function evals when instructed to use 551", "passing", "not yet run", "not yet run", "not yet run", "not yet run", "passing", "passing", "passing", "passing", "passing", "passing", "Black took 555 function evals when instructed to use 552", "passing", "passing", "passing", "passing", "Black took 588 function evals when instructed to use 552", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 76, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 103, in freelunch_krillherd_3_cube\n    return freelunch_factory(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 35, in freelunch_factory\n    runs = optimizer(nruns=1, full_output=True)  # instance and run\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 45, in __call__\n    sols = self.run()\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/optimisers.py\", line 469, in run\n    pop[i].fitness = self.obj(dna)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 89, in w_obj\n    fit = obj(vec)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 22, in _objective\n    return objective(x)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 87, in markowitz_analytic_on_cube\n    assert all([ 0<=ui<=1 for ui in u])\nAssertionError\n", "Traceback (most recent call last):\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/comparison/eloratings.py\", line 76, in optimizer_game\n    black_best_val, black_best_x, black_feval_count = black(objective, n_trials=n_black_trials,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 108, in freelunch_krillherd_8_cube\n    return freelunch_factory(objective=objective, n_trials=n_trials, n_dim=n_dim, with_count=with_count,\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 35, in freelunch_factory\n    runs = optimizer(nruns=1, full_output=True)  # instance and run\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 45, in __call__\n    sols = self.run()\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/optimisers.py\", line 469, in run\n    pop[i].fitness = self.obj(dna)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/freelunch/base.py\", line 89, in w_obj\n    fit = obj(vec)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/optimizers/freelunchcube.py\", line 22, in _objective\n    return objective(x)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 174, in markowitz_return_on_cube\n    return realized_something_factory(g=g,u=u, adjust=True)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 121, in realized_something_factory\n    w = cube_to_weights(u)\n  File \"/Users/petercotton/virtual-envs/optimizer-elo-ratings/lib/python3.8/site-packages/humpday/objectives/portfolio.py\", line 108, in cube_to_weights\n    raise ValueError(\"u should be in hypercube\")\nValueError: u should be in hypercube\n"], "active": [true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]}